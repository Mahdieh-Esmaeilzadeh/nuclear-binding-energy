{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4e1e3d",
   "metadata": {},
   "source": [
    "# model_experiments\n",
    "\n",
    "این نوت‌بوک شامل بخش‌های مربوط به ساخت، آموزش، و ارزیابی مدل‌ها برای پیش‌بینی انرژی بایندینگ است. محتوای این فایل از `BindingEnergy.ipynb` استخراج شده است."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bbc7e4",
   "metadata": {
    "id": "HquI0kv2P-dz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, callbacks\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"/content/data.csv\"\n",
    "ARTIFACT_DIR = \"./artifacts\"\n",
    "CKPT_DIR = os.path.join(ARTIFACT_DIR, \"checkpoints\")\n",
    "PLOTS_DIR = os.path.join(ARTIFACT_DIR, \"plots\")\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_COLUMN = \"binding_energy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2513b",
   "metadata": {
    "id": "Nr4awaQAhGP6"
   },
   "source": [
    "##3. Stratified Train/Test Split for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd32ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dper5i2Ty3y",
    "outputId": "6c21ec54-f45b-4a15-ec83-8afac0e7e35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (2720, 15), Test shape: (680, 15)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    y_bins = pd.qcut(y, q=10, duplicates=\"drop\", labels=False)\n",
    "except Exception:\n",
    "    # Fallback if qcut fails (e.g., too many duplicates)\n",
    "    y_bins = pd.cut(y, bins=10, labels=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test, bins_train, bins_test = train_test_split(\n",
    "    X, y, y_bins,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_bins\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f8532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdu78SCQT2dE",
    "outputId": "b6e57edf-a024-487f-8f18-bd063a4e8a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed feature matrix: train=(2720, 67), test=(680, 67)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(\n",
    "    handle_unknown=\"ignore\",\n",
    "    min_frequency=0.01\n",
    ")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"power\", PowerTransformer(method=\"yeo-johnson\", standardize=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", ohe)\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"  # keep only specified columns\n",
    ")\n",
    "\n",
    "# Fit preprocessing on TRAIN ONLY to avoid leakage\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Transform\n",
    "X_train_proc = preprocessor.transform(X_train).toarray()\n",
    "X_test_proc = preprocessor.transform(X_test).toarray()\n",
    "\n",
    "# Feature names (for reference)\n",
    "try:\n",
    "    feature_names = preprocessor.get_feature_names_out().tolist()\n",
    "except Exception:\n",
    "    feature_names = [f\"f{i}\" for i in range(X_train_proc.shape[1])]\n",
    "\n",
    "print(f\"\\nProcessed feature matrix: train={X_train_proc.shape}, test={X_test_proc.shape}\")\n",
    "\n",
    "# Save preprocessor and metadata\n",
    "joblib.dump(preprocessor, os.path.join(ARTIFACT_DIR, \"preprocessor.pkl\"))\n",
    "with open(os.path.join(ARTIFACT_DIR, \"feature_names.json\"), \"w\") as f:\n",
    "    json.dump(feature_names, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4d83d",
   "metadata": {
    "id": "xSCsVbGwhoqq"
   },
   "source": [
    "##5. Optional Target Scaling (stabilizes training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fba76",
   "metadata": {
    "id": "RR53BjP3hvzt"
   },
   "source": [
    "##6. Model Architecture (Residual MLP with regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5968c07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "STdEXIG2T_hj",
    "outputId": "9a4973ea-aa9d-4187-bb9b-508e0683fdf8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResidualMLPRegressor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResidualMLPRegressor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ features            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │ features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ y_scaled (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ features            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m17,408\u001b[0m │ features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ y_scaled (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">419,585</span> (1.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m419,585\u001b[0m (1.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">416,001</span> (1.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m416,001\u001b[0m (1.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> (14.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,584\u001b[0m (14.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(input_dim: int,\n",
    "                width: int = 256,\n",
    "                blocks: int = 3,\n",
    "                dropout: float = 0.2,\n",
    "                l2_reg: float = 1e-4,\n",
    "                lr: float = 1e-3,\n",
    "                weight_decay: float = 1e-5) -> tf.keras.Model:\n",
    "    inp = layers.Input(shape=(input_dim,), name=\"features\")\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Dense(width, kernel_initializer=\"he_normal\",\n",
    "                     kernel_regularizer=regularizers.l2(l2_reg))(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"gelu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    # Residual blocks (keep same width to allow skip connections)\n",
    "    for i in range(blocks):\n",
    "        shortcut = x\n",
    "        y = layers.Dense(width, kernel_initializer=\"he_normal\",\n",
    "                         kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        y = layers.Activation(\"gelu\")(y)\n",
    "        y = layers.Dropout(dropout)(y)\n",
    "\n",
    "        y = layers.Dense(width, kernel_initializer=\"he_normal\",\n",
    "                         kernel_regularizer=regularizers.l2(l2_reg))(y)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        # Pre-activation residual connection\n",
    "        x = layers.Add()([shortcut, y])\n",
    "        x = layers.Activation(\"gelu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    # Head\n",
    "    out = layers.Dense(1, name=\"y_scaled\")(x)\n",
    "\n",
    "    # Optimizer: AdamW if available, else Adam\n",
    "    try:\n",
    "        opt = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=weight_decay)\n",
    "    except Exception:\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out, name=\"ResidualMLPRegressor\")\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"mse\",\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "                 tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "    input_dim=X_train_proc.shape[1],\n",
    "    width=256,\n",
    "    blocks=3,\n",
    "    dropout=0.25,\n",
    "    l2_reg=1e-4,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4521c5d9",
   "metadata": {
    "id": "QQnz3fJgh4Dg"
   },
   "source": [
    "##7. Training with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b27e87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsyG45DeUCOK",
    "outputId": "00f6cfaf-d4aa-449e-f67e-38e40f30b286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1178 - mae: 0.1273 - rmse: 0.2019\n",
      "Epoch 1: val_loss improved from inf to 0.16864, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1197 - mae: 0.1282 - rmse: 0.2066 - val_loss: 0.1686 - val_mae: 0.1260 - val_rmse: 0.3044 - learning_rate: 6.2500e-05\n",
      "Epoch 2/500\n",
      "\u001b[1m28/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1162 - mae: 0.1248 - rmse: 0.1999\n",
      "Epoch 2: val_loss improved from 0.16864 to 0.15359, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1180 - mae: 0.1250 - rmse: 0.2043 - val_loss: 0.1536 - val_mae: 0.1168 - val_rmse: 0.2789 - learning_rate: 6.2500e-05\n",
      "Epoch 3/500\n",
      "\u001b[1m28/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1137 - mae: 0.1195 - rmse: 0.1928\n",
      "Epoch 3: val_loss improved from 0.15359 to 0.15356, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1148 - mae: 0.1200 - rmse: 0.1961 - val_loss: 0.1536 - val_mae: 0.1197 - val_rmse: 0.2791 - learning_rate: 6.2500e-05\n",
      "Epoch 4/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1021 - mae: 0.1107 - rmse: 0.1607\n",
      "Epoch 4: val_loss did not improve from 0.15356\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1035 - mae: 0.1121 - rmse: 0.1651 - val_loss: 0.1540 - val_mae: 0.1230 - val_rmse: 0.2801 - learning_rate: 6.2500e-05\n",
      "Epoch 5/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1078 - mae: 0.1160 - rmse: 0.1791\n",
      "Epoch 5: val_loss did not improve from 0.15356\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1083 - mae: 0.1162 - rmse: 0.1805 - val_loss: 0.1576 - val_mae: 0.1175 - val_rmse: 0.2867 - learning_rate: 6.2500e-05\n",
      "Epoch 6/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1129 - mae: 0.1169 - rmse: 0.1926\n",
      "Epoch 6: val_loss improved from 0.15356 to 0.14577, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1130 - mae: 0.1170 - rmse: 0.1930 - val_loss: 0.1458 - val_mae: 0.1181 - val_rmse: 0.2656 - learning_rate: 6.2500e-05\n",
      "Epoch 7/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1061 - mae: 0.1128 - rmse: 0.1745\n",
      "Epoch 7: val_loss did not improve from 0.14577\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1074 - mae: 0.1135 - rmse: 0.1782 - val_loss: 0.1470 - val_mae: 0.1216 - val_rmse: 0.2682 - learning_rate: 6.2500e-05\n",
      "Epoch 8/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1033 - mae: 0.1106 - rmse: 0.1677\n",
      "Epoch 8: val_loss improved from 0.14577 to 0.14554, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1038 - mae: 0.1108 - rmse: 0.1692 - val_loss: 0.1455 - val_mae: 0.1197 - val_rmse: 0.2657 - learning_rate: 6.2500e-05\n",
      "Epoch 9/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1097 - mae: 0.1183 - rmse: 0.1862\n",
      "Epoch 9: val_loss improved from 0.14554 to 0.14359, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1109 - mae: 0.1186 - rmse: 0.1893 - val_loss: 0.1436 - val_mae: 0.1158 - val_rmse: 0.2623 - learning_rate: 6.2500e-05\n",
      "Epoch 10/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1067 - mae: 0.1124 - rmse: 0.1778\n",
      "Epoch 10: val_loss did not improve from 0.14359\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1078 - mae: 0.1130 - rmse: 0.1808 - val_loss: 0.1541 - val_mae: 0.1228 - val_rmse: 0.2818 - learning_rate: 6.2500e-05\n",
      "Epoch 11/500\n",
      "\u001b[1m27/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1121 - mae: 0.1155 - rmse: 0.1931\n",
      "Epoch 11: val_loss did not improve from 0.14359\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1121 - mae: 0.1160 - rmse: 0.1933 - val_loss: 0.1459 - val_mae: 0.1161 - val_rmse: 0.2672 - learning_rate: 6.2500e-05\n",
      "Epoch 12/500\n",
      "\u001b[1m31/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1049 - mae: 0.1131 - rmse: 0.1738\n",
      "Epoch 12: val_loss did not improve from 0.14359\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1058 - mae: 0.1135 - rmse: 0.1762 - val_loss: 0.1465 - val_mae: 0.1142 - val_rmse: 0.2686 - learning_rate: 6.2500e-05\n",
      "Epoch 13/500\n",
      "\u001b[1m31/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1116 - mae: 0.1183 - rmse: 0.1923\n",
      "Epoch 13: val_loss did not improve from 0.14359\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1120 - mae: 0.1185 - rmse: 0.1934 - val_loss: 0.1484 - val_mae: 0.1147 - val_rmse: 0.2723 - learning_rate: 6.2500e-05\n",
      "Epoch 14/500\n",
      "\u001b[1m31/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1037 - mae: 0.1166 - rmse: 0.1713\n",
      "Epoch 14: val_loss did not improve from 0.14359\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1043 - mae: 0.1168 - rmse: 0.1732 - val_loss: 0.1506 - val_mae: 0.1214 - val_rmse: 0.2767 - learning_rate: 6.2500e-05\n",
      "Epoch 15/500\n",
      "\u001b[1m26/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0996 - mae: 0.1074 - rmse: 0.1585\n",
      "Epoch 15: val_loss improved from 0.14359 to 0.13950, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1013 - mae: 0.1092 - rmse: 0.1640 - val_loss: 0.1395 - val_mae: 0.1159 - val_rmse: 0.2561 - learning_rate: 6.2500e-05\n",
      "Epoch 16/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1037 - mae: 0.1116 - rmse: 0.1720\n",
      "Epoch 16: val_loss did not improve from 0.13950\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1043 - mae: 0.1121 - rmse: 0.1737 - val_loss: 0.1445 - val_mae: 0.1181 - val_rmse: 0.2661 - learning_rate: 6.2500e-05\n",
      "Epoch 17/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1034 - mae: 0.1117 - rmse: 0.1719\n",
      "Epoch 17: val_loss did not improve from 0.13950\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1040 - mae: 0.1118 - rmse: 0.1735 - val_loss: 0.1466 - val_mae: 0.1199 - val_rmse: 0.2702 - learning_rate: 6.2500e-05\n",
      "Epoch 18/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0981 - mae: 0.1059 - rmse: 0.1556\n",
      "Epoch 18: val_loss improved from 0.13950 to 0.13786, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0992 - mae: 0.1069 - rmse: 0.1593 - val_loss: 0.1379 - val_mae: 0.1141 - val_rmse: 0.2538 - learning_rate: 6.2500e-05\n",
      "Epoch 19/500\n",
      "\u001b[1m31/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1036 - mae: 0.1077 - rmse: 0.1721\n",
      "Epoch 19: val_loss did not improve from 0.13786\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1039 - mae: 0.1079 - rmse: 0.1733 - val_loss: 0.1446 - val_mae: 0.1193 - val_rmse: 0.2670 - learning_rate: 6.2500e-05\n",
      "Epoch 20/500\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1017 - mae: 0.1093 - rmse: 0.1675\n",
      "Epoch 20: val_loss did not improve from 0.13786\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1022 - mae: 0.1096 - rmse: 0.1689 - val_loss: 0.1482 - val_mae: 0.1219 - val_rmse: 0.2740 - learning_rate: 6.2500e-05\n",
      "Epoch 21/500\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1085 - mae: 0.1111 - rmse: 0.1876\n",
      "Epoch 21: val_loss did not improve from 0.13786\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1085 - mae: 0.1111 - rmse: 0.1877 - val_loss: 0.1386 - val_mae: 0.1153 - val_rmse: 0.2560 - learning_rate: 6.2500e-05\n",
      "Epoch 22/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0969 - mae: 0.1059 - rmse: 0.1538\n",
      "Epoch 22: val_loss did not improve from 0.13786\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0982 - mae: 0.1070 - rmse: 0.1579 - val_loss: 0.1426 - val_mae: 0.1190 - val_rmse: 0.2641 - learning_rate: 6.2500e-05\n",
      "Epoch 23/500\n",
      "\u001b[1m28/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1000 - mae: 0.1097 - rmse: 0.1637\n",
      "Epoch 23: val_loss improved from 0.13786 to 0.13469, saving model to ./artifacts/checkpoints/best_model.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1004 - mae: 0.1101 - rmse: 0.1652 - val_loss: 0.1347 - val_mae: 0.1132 - val_rmse: 0.2490 - learning_rate: 6.2500e-05\n",
      "Epoch 24/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1002 - mae: 0.1102 - rmse: 0.1652\n",
      "Epoch 24: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1012 - mae: 0.1110 - rmse: 0.1682 - val_loss: 0.1571 - val_mae: 0.1258 - val_rmse: 0.2908 - learning_rate: 6.2500e-05\n",
      "Epoch 25/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0998 - mae: 0.1106 - rmse: 0.1648\n",
      "Epoch 25: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1006 - mae: 0.1114 - rmse: 0.1673 - val_loss: 0.1540 - val_mae: 0.1220 - val_rmse: 0.2857 - learning_rate: 6.2500e-05\n",
      "Epoch 26/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1008 - mae: 0.1078 - rmse: 0.1682\n",
      "Epoch 26: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1010 - mae: 0.1081 - rmse: 0.1689 - val_loss: 0.1516 - val_mae: 0.1240 - val_rmse: 0.2817 - learning_rate: 6.2500e-05\n",
      "Epoch 27/500\n",
      "\u001b[1m28/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1013 - mae: 0.1149 - rmse: 0.1702\n",
      "Epoch 27: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1017 - mae: 0.1148 - rmse: 0.1713 - val_loss: 0.1541 - val_mae: 0.1230 - val_rmse: 0.2864 - learning_rate: 6.2500e-05\n",
      "Epoch 28/500\n",
      "\u001b[1m28/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0919 - mae: 0.1014 - rmse: 0.1401\n",
      "Epoch 28: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0933 - mae: 0.1027 - rmse: 0.1448 - val_loss: 0.1484 - val_mae: 0.1187 - val_rmse: 0.2766 - learning_rate: 6.2500e-05\n",
      "Epoch 29/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0989 - mae: 0.1092 - rmse: 0.1640\n",
      "Epoch 29: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0996 - mae: 0.1093 - rmse: 0.1659 - val_loss: 0.1575 - val_mae: 0.1231 - val_rmse: 0.2928 - learning_rate: 6.2500e-05\n",
      "Epoch 30/500\n",
      "\u001b[1m31/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1023 - mae: 0.1079 - rmse: 0.1738\n",
      "Epoch 30: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1027 - mae: 0.1084 - rmse: 0.1752 - val_loss: 0.1388 - val_mae: 0.1127 - val_rmse: 0.2591 - learning_rate: 6.2500e-05\n",
      "Epoch 31/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1027 - mae: 0.1105 - rmse: 0.1760\n",
      "Epoch 31: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1028 - mae: 0.1108 - rmse: 0.1764 - val_loss: 0.1493 - val_mae: 0.1194 - val_rmse: 0.2791 - learning_rate: 6.2500e-05\n",
      "Epoch 32/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0980 - mae: 0.1085 - rmse: 0.1625\n",
      "Epoch 32: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0987 - mae: 0.1090 - rmse: 0.1649 - val_loss: 0.1387 - val_mae: 0.1137 - val_rmse: 0.2595 - learning_rate: 6.2500e-05\n",
      "Epoch 33/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1014 - mae: 0.1081 - rmse: 0.1723\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1022 - mae: 0.1090 - rmse: 0.1748 - val_loss: 0.1421 - val_mae: 0.1184 - val_rmse: 0.2663 - learning_rate: 6.2500e-05\n",
      "Epoch 34/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0955 - mae: 0.1072 - rmse: 0.1555\n",
      "Epoch 34: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0961 - mae: 0.1075 - rmse: 0.1576 - val_loss: 0.1468 - val_mae: 0.1188 - val_rmse: 0.2752 - learning_rate: 3.1250e-05\n",
      "Epoch 35/500\n",
      "\u001b[1m26/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0962 - mae: 0.1066 - rmse: 0.1582\n",
      "Epoch 35: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0968 - mae: 0.1070 - rmse: 0.1601 - val_loss: 0.1461 - val_mae: 0.1190 - val_rmse: 0.2741 - learning_rate: 3.1250e-05\n",
      "Epoch 36/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0980 - mae: 0.1119 - rmse: 0.1638\n",
      "Epoch 36: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0982 - mae: 0.1118 - rmse: 0.1647 - val_loss: 0.1531 - val_mae: 0.1250 - val_rmse: 0.2867 - learning_rate: 3.1250e-05\n",
      "Epoch 37/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1004 - mae: 0.1073 - rmse: 0.1712\n",
      "Epoch 37: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1010 - mae: 0.1077 - rmse: 0.1728 - val_loss: 0.1360 - val_mae: 0.1166 - val_rmse: 0.2553 - learning_rate: 3.1250e-05\n",
      "Epoch 38/500\n",
      "\u001b[1m31/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1015 - mae: 0.1099 - rmse: 0.1743\n",
      "Epoch 38: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1016 - mae: 0.1099 - rmse: 0.1747 - val_loss: 0.1475 - val_mae: 0.1233 - val_rmse: 0.2771 - learning_rate: 3.1250e-05\n",
      "Epoch 39/500\n",
      "\u001b[1m27/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0954 - mae: 0.1050 - rmse: 0.1565\n",
      "Epoch 39: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0960 - mae: 0.1057 - rmse: 0.1584 - val_loss: 0.1479 - val_mae: 0.1240 - val_rmse: 0.2779 - learning_rate: 3.1250e-05\n",
      "Epoch 40/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1043 - mae: 0.1110 - rmse: 0.1821\n",
      "Epoch 40: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1046 - mae: 0.1111 - rmse: 0.1832 - val_loss: 0.1428 - val_mae: 0.1207 - val_rmse: 0.2688 - learning_rate: 3.1250e-05\n",
      "Epoch 41/500\n",
      "\u001b[1m30/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1002 - mae: 0.1066 - rmse: 0.1708\n",
      "Epoch 41: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1007 - mae: 0.1068 - rmse: 0.1722 - val_loss: 0.1493 - val_mae: 0.1217 - val_rmse: 0.2807 - learning_rate: 3.1250e-05\n",
      "Epoch 42/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0985 - mae: 0.1075 - rmse: 0.1668\n",
      "Epoch 42: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0988 - mae: 0.1076 - rmse: 0.1679 - val_loss: 0.1401 - val_mae: 0.1194 - val_rmse: 0.2640 - learning_rate: 3.1250e-05\n",
      "Epoch 43/500\n",
      "\u001b[1m25/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0909 - mae: 0.1015 - rmse: 0.1420\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0921 - mae: 0.1032 - rmse: 0.1464 - val_loss: 0.1399 - val_mae: 0.1202 - val_rmse: 0.2638 - learning_rate: 3.1250e-05\n",
      "Epoch 44/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0932 - mae: 0.1019 - rmse: 0.1506\n",
      "Epoch 44: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0937 - mae: 0.1027 - rmse: 0.1524 - val_loss: 0.1445 - val_mae: 0.1227 - val_rmse: 0.2724 - learning_rate: 1.5625e-05\n",
      "Epoch 45/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1003 - mae: 0.1114 - rmse: 0.1729\n",
      "Epoch 45: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1003 - mae: 0.1114 - rmse: 0.1730 - val_loss: 0.1425 - val_mae: 0.1215 - val_rmse: 0.2687 - learning_rate: 1.5625e-05\n",
      "Epoch 46/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0929 - mae: 0.1024 - rmse: 0.1495\n",
      "Epoch 46: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0938 - mae: 0.1034 - rmse: 0.1526 - val_loss: 0.1412 - val_mae: 0.1196 - val_rmse: 0.2663 - learning_rate: 1.5625e-05\n",
      "Epoch 47/500\n",
      "\u001b[1m27/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0989 - mae: 0.1075 - rmse: 0.1689\n",
      "Epoch 47: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0985 - mae: 0.1075 - rmse: 0.1678 - val_loss: 0.1431 - val_mae: 0.1216 - val_rmse: 0.2701 - learning_rate: 1.5625e-05\n",
      "Epoch 48/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0947 - mae: 0.1044 - rmse: 0.1564\n",
      "Epoch 48: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0956 - mae: 0.1052 - rmse: 0.1591 - val_loss: 0.1450 - val_mae: 0.1227 - val_rmse: 0.2736 - learning_rate: 1.5625e-05\n",
      "Epoch 49/500\n",
      "\u001b[1m27/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0956 - mae: 0.1086 - rmse: 0.1587\n",
      "Epoch 49: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0971 - mae: 0.1094 - rmse: 0.1634 - val_loss: 0.1451 - val_mae: 0.1215 - val_rmse: 0.2739 - learning_rate: 1.5625e-05\n",
      "Epoch 50/500\n",
      "\u001b[1m26/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0963 - mae: 0.1032 - rmse: 0.1610\n",
      "Epoch 50: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0978 - mae: 0.1045 - rmse: 0.1657 - val_loss: 0.1422 - val_mae: 0.1196 - val_rmse: 0.2686 - learning_rate: 1.5625e-05\n",
      "Epoch 51/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1033 - mae: 0.1103 - rmse: 0.1814\n",
      "Epoch 51: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1039 - mae: 0.1107 - rmse: 0.1831 - val_loss: 0.1413 - val_mae: 0.1206 - val_rmse: 0.2669 - learning_rate: 1.5625e-05\n",
      "Epoch 52/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0945 - mae: 0.1057 - rmse: 0.1556\n",
      "Epoch 52: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0954 - mae: 0.1062 - rmse: 0.1585 - val_loss: 0.1434 - val_mae: 0.1215 - val_rmse: 0.2709 - learning_rate: 1.5625e-05\n",
      "Epoch 53/500\n",
      "\u001b[1m29/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0951 - mae: 0.1050 - rmse: 0.1582\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.13469\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0955 - mae: 0.1053 - rmse: 0.1596 - val_loss: 0.1408 - val_mae: 0.1196 - val_rmse: 0.2662 - learning_rate: 1.5625e-05\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\n",
      "Loaded best model from checkpoint.\n"
     ]
    }
   ],
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=30,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ckpt_path = os.path.join(CKPT_DIR, \"best_model.keras\")\n",
    "model_ckpt = callbacks.ModelCheckpoint(\n",
    "    filepath=ckpt_path,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train_scaled,\n",
    "    validation_split=0.2,  # validation from TRAIN only\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, reduce_lr, model_ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load best checkpoint (safeguard)\n",
    "best_model = tf.keras.models.load_model(ckpt_path)\n",
    "print(\"\\nLoaded best model from checkpoint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8ad34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyed5bBwUEqN",
    "outputId": "fbf478c2-1447-4df3-f1f2-6d67ac53c471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Test Metrics (scaled target) ==========\n",
      "Loss (MSE): 0.163377\n",
      "MAE:        0.125585\n",
      "RMSE:       0.301150\n",
      "\n",
      "========== Test Metrics (original target) ==========\n",
      "MAE:  65.136266\n",
      "MSE:  24396.891355\n",
      "RMSE: 156.195043\n",
      "R^2:  0.919825\n"
     ]
    }
   ],
   "source": [
    "eval_results = best_model.evaluate(X_test_proc, y_test_scaled, verbose=0)\n",
    "print(\"\\n========== Test Metrics (scaled target) ==========\")\n",
    "print(f\"Loss (MSE): {eval_results[0]:.6f}\")\n",
    "print(f\"MAE:        {eval_results[1]:.6f}\")\n",
    "print(f\"RMSE:       {eval_results[2]:.6f}\")\n",
    "\n",
    "# Predictions -> inverse scale to original units\n",
    "y_pred_scaled = best_model.predict(X_test_proc, verbose=0)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = np.mean(np.abs(y_test.values.reshape(-1, 1) - y_pred))\n",
    "\n",
    "print(\"\\n========== Test Metrics (original target) ==========\")\n",
    "print(f\"MAE:  {mae:.6f}\")\n",
    "print(f\"MSE:  {mse:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"R^2:  {r2:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f9dde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWRZt18VUMF5",
    "outputId": "90f82554-59ba-41b2-f2ba-4d7add8d0ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved final model to: ./artifacts/final_model.keras\n",
      "\n",
      "Training and evaluation completed successfully!\n",
      "Artifacts saved in: ./artifacts\n"
     ]
    }
   ],
   "source": [
    "final_model_path = os.path.join(ARTIFACT_DIR, \"final_model.keras\")\n",
    "best_model.save(final_model_path)\n",
    "print(f\"\\nSaved final model to: {final_model_path}\")\n",
    "\n",
    "# Save run metadata\n",
    "metadata = {\n",
    "    \"input_dim\": int(X_train_proc.shape[1]),\n",
    "    \"numeric_cols\": numeric_cols,\n",
    "    \"categorical_cols\": categorical_cols,\n",
    "    \"train_shape\": list(X_train.shape),\n",
    "    \"test_shape\": list(X_test.shape),\n",
    "    \"metrics\": {\n",
    "        \"mae\": float(mae),\n",
    "        \"mse\": float(mse),\n",
    "        \"rmse\": float(rmse),\n",
    "        \"r2\": float(r2)\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(ARTIFACT_DIR, \"run_metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\nTraining and evaluation completed successfully!\")\n",
    "print(f\"Artifacts saved in: {ARTIFACT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
